# Interview Template Version 1: Data Scientists

This version is tailored for data science experts to understand their expectations regarding analytical methods, associated knowledge, and data science workflows.

---

## 1. General Understanding and Use Cases
- What are the primary use cases for time series analysis in your projects?
- What types of time series data do you work with (e.g., univariate, multivariate, irregular)?
- What are the biggest challenges you encounter when analyzing time series data?
- Do you currently use any tools, ontologies, or frameworks to support your time series analysis? If yes, which ones, and what are their strengths/limitations?
- How important is it to semantically represent information of specific time intervals within your time series data?
- Are you reusing previously derived knowledge in your analyses?
- How important is the inclusion of expert knowledge and scenario-specific facts?

---

## 2. Time Series Representation
- How do you currently define and identify meaningful subsequences within your time series (e.g., statistical thresholds, clustering, domain rules)?
- Are overlapping or hierarchical time series subsequences relevant to your analysis? If yes, how do you handle them?
- What types of features or attributes are most important when characterizing time series (e.g., trends, anomalies, motifs)?
- How do you annotate or label time series in your data?

---

## 3. Knowledge Categorization and Representation
- How do you currently document insights derived from your analysis (e.g., anomalies, trends, statistical summaries)?
- What types of time series knowledge should the ontology contain?
- How would you categorize knowledge to align with individual stages in the analysis workflows?
- Do you need to keep track of specific models or methods after time series analyses?

---

## 4. Data Analysis and Methodological Requirements
- What analytical methods or algorithms do you most often use for time series analysis (e.g., clustering, anomaly detection, forecasting)?
- How do you manage metadata about the methods used in your analyses (e.g., algorithm parameters, evaluation metrics)?
- Would it help to have specific methodical suggestions from previous analyses available?

---

## 5. Semantic and Ontological Features
- Do you require the ontology to integrate with external datasets or metadata?
- Is there specific information that the ontology should consider?
- Should the ontology support linking knowledge across time series?

---

## 6. Validation and Evaluation
- How would you assess whether the ontology meets your needs?
- What specific scenarios or datasets would you use to test the ontology?
- Are there any metrics you use to evaluate the quality of knowledge representation?

---

## 7. Closing Questions
- Is there any additional functionality you would like the ontology to provide?
- Do you foresee any challenges in integrating the ontology into your current workflows?